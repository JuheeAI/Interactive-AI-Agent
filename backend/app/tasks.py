import time
import json
import base64
import io
import os
import requests
from PIL import Image
from celery import Celery
import wandb
import torch

try:
    from .tools.agent_prompt import AGENT_PROMPT
except ImportError:
    AGENT_PROMPT = """
    You are an AI task planner. Output strictly JSON.
    """

from .tools.vqa_tool import run_vqa
from .tools.object_detection_tool import run_object_detection

try:
    from .tools.sam_tool import run_sam_box as run_sam
except ImportError:
    from .tools.sam_tool import run_sam

from .tools.sd_tool import run_inpainting  
from .tools.evaluation_tool import calculate_clip_score

# --- ì„¤ì • ---
broker_url = os.environ.get("CELERY_BROKER_URL", "redis://localhost:6379/0")
backend_url = os.environ.get("CELERY_RESULT_BACKEND", "redis://localhost:6379/0")

celery_app = Celery(
    'tasks',
    broker=broker_url,
    backend=backend_url
)
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

@celery_app.task(bind=True)
def run_agent_task(self, prompt: str, image_data: str):
    task_start_time = time.time()

    # GPU ë©”ëª¨ë¦¬ ì¸¡ì • ì´ˆê¸°í™” (ì´ì „ ì‘ì—…ì˜ ê¸°ë¡ ì‚­ì œ)
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()

    wandb.init(project="ai_agent_project", name=f"job_{self.request.id}", reinit=True)
    
    try:
        image_bytes = base64.b64decode(image_data)
        original_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        
        print(f"ğŸ§  LLM: '{prompt}'ì— ëŒ€í•œ ê³„íš ìˆ˜ë¦½ ì¤‘...")

        llm_start = time.time()
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
        payload = {
            "model": "gpt-4o",
            "messages": [
                {"role": "system", "content": AGENT_PROMPT},
                {"role": "user", "content": prompt}
            ],
            "response_format": {"type": "json_object"}
        }

        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
        plan = json.loads(response.json()['choices'][0]['message']['content']).get('plan', [])
        
        llm_duration = time.time() - llm_start
        wandb.log({"timer/llm_planning": llm_duration}) 
        
        print(f"ğŸ“‹ ê³„íš: {json.dumps(plan, indent=2)}")

        last_result = None
        final_data = None
        
        # CLIP í‰ê°€ë¥¼ ìœ„í•´ 'ëª©í‘œ í”„ë¡¬í”„íŠ¸'ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        target_prompt = "" 
        
        for idx, step in enumerate(plan):
            tool = step['tool_name']
            params = step['parameters']
            print(f"ğŸš€ [Step {idx+1}] {tool} ì‹¤í–‰ ì¤‘...")

            for k, v in params.items():
                if v == "[PREVIOUS_STEP_RESULT]": params[k] = last_result
                elif v == "[ORIGINAL_IMAGE]": params[k] = original_image

            # --- ë„êµ¬ ë¶„ê¸° ì²˜ë¦¬ ---
            start_t = time.time()
            
            if tool == "run_object_detection":
                last_result = run_object_detection(original_image, params['query'])
                if not last_result: raise Exception("ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                print(f"ì¢Œí‘œ: {last_result}")

            elif tool == "run_sam":
                last_result = run_sam(original_image, last_result)
                print("ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ")
                if isinstance(last_result, Image.Image):
                     wandb.log({f"step_{idx}_mask": wandb.Image(last_result)})

            elif tool == "run_inpainting":
                print("SD3 ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
                # ìƒì„±ì— ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ ì €ì¥ (í‰ê°€ìš©)
                target_prompt = params['prompt']
                
                last_result = run_inpainting(params['image'], params['mask_image'], params['prompt'])
                final_data = last_result
                if isinstance(last_result, Image.Image):
                     wandb.log({f"step_{idx}_result": wandb.Image(last_result)})

            elif tool == "run_vqa":
                last_result = run_vqa(original_image, params['question'])
                final_data = last_result
            
            duration = time.time() - start_t
            wandb.log({f"timer/{tool}": duration})
            print(f"[Step {idx+1}] ì™„ë£Œ ({duration:.2f}s)")

        total_latency = time.time() - task_start_time

        # --- ì •ëŸ‰ì  í‰ê°€ ì§€í‘œ ì¸¡ì • ---
        metrics = {"timer/total_latency": total_latency}

        # 1. GPU Peak Memory ì¸¡ì • (MB)
        if torch.cuda.is_available():
            peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)
            metrics["system/peak_gpu_memory_mb"] = peak_memory
            print(f"GPU Peak Memory: {peak_memory:.2f} MB")

        # 2. CLIP Score ì¸¡ì • (ì´ë¯¸ì§€ ìƒì„± ì‘ì—…ì´ì—ˆì„ ê²½ìš°)
        if isinstance(final_data, Image.Image) and target_prompt:
            clip_score = calculate_clip_score(final_data, target_prompt)
            metrics["evaluation/clip_score"] = clip_score
            metrics["evaluation/target_prompt"] = target_prompt
            print(f"CLIP Score: {clip_score} (Prompt: {target_prompt})")
        
        # ì§€í‘œ ì „ì†¡
        wandb.log(metrics)
        wandb.finish()
        
        # ìµœì¢… ê²°ê³¼ ë°˜í™˜
        result_payload = {
            "status": "success",
            "metrics": metrics 
        }

        if isinstance(final_data, Image.Image):
            buf = io.BytesIO()
            final_data.save(buf, format="JPEG")
            result_payload["type"] = "image"
            result_payload["data"] = base64.b64encode(buf.getvalue()).decode()
        else:
            result_payload["type"] = "text"
            result_payload["data"] = str(final_data)
            
        return result_payload

    except Exception as e:
        print(f"ì—ëŸ¬ ë°œìƒ: {e}")
        wandb.finish()
        return {"status": "error", "error": str(e)}