import multiprocessing
import os
import torch
import logging
from PIL import Image
from diffusers import Flux2Pipeline, DiffusionPipeline
# from torch.profiler import profile, record_function, ProfilerActivity
import requests
import io
import time


# PROFILE_OUTPUT_DIR = "profiler_output" 
# os.makedirs(PROFILE_OUTPUT_DIR, exist_ok=True)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹ ì„¤ì •
try:
    multiprocessing.set_start_method('spawn', force=True)
except RuntimeError:
    pass

MY_HF_TOKEN = os.environ.get("HUGGING_FACE_TOKEN")

class Flux2ImageGenerator:
    _instance = None
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(Flux2ImageGenerator, cls).__new__(cls)
            cls._instance._is_loaded = False
        return cls._instance

    def __init__(self):
        if self._is_loaded:
            return
        self.pipeline = None
        self._is_loaded = True

    def _remote_text_encoder(self, prompt: str):
        if not prompt: return None
        device = "cuda" if torch.cuda.is_available() else "cpu"
        api_url = "https://remote-text-encoder-flux-2.huggingface.co/predict"

        encoder_start_time = time.time()
        logger.info(f"Sending prompt to Remote API: {api_url}")
        
        try:
            response = requests.post(
                api_url,
                json={"prompt": prompt},
                headers={
                    "Authorization": f"Bearer {MY_HF_TOKEN}",
                    "Content-Type": "application/json"
                },
                timeout=120
            )

            encoder_duration = time.time() - encoder_start_time
            
            if response.status_code != 200:
                logger.error(f"API Error ({response.status_code}): {response.text}")
                return None
                
            data = torch.load(io.BytesIO(response.content))
            
            if isinstance(data, (tuple, list)):
                return data[0].to(device)
            else:
                return data.to(device)

        except Exception as e:
            encoder_duration = time.time() - encoder_start_time
            logger.error(f"Remote Encoder Failed: {e}")
            logger.error(f"âŒ Remote Encoder Exception Time: {encoder_duration:.2f}s")
            return None

    def load_pipeline(self):
        """FLUX.2 Img2Img íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.pipeline is not None:
            return self.pipeline

        logger.info("âš¡ FLUX.2 Img2Img ëª¨ë¸ ë¡œë“œ ì¤‘ (Text EncoderëŠ” Remote ì‚¬ìš©)...")

        # FLUX.2 ëª¨ë¸ ë¡œë“œ (Text EncoderëŠ” ì›ê²©ìœ¼ë¡œ ëŒ€ì²´í•˜ë¯€ë¡œ None)
        self.pipeline = Flux2Pipeline.from_pretrained(
            "diffusers/FLUX.2-dev-bnb-4bit",
            # text_encoder=None,
            torch_dtype=torch.bfloat16 
        ).to("cuda")

        logger.info("ëª¨ë¸ ì»´íŒŒì¼ ì¤‘...")
        try:
            self.pipeline.transformer = torch.compile(
                self.pipeline.transformer, 
                mode="reduce-overhead", 
                fullgraph=True
            )
            logger.info("ì»´íŒŒì¼ ì„±ê³µ.")
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ì»´íŒŒì¼ ì‹¤íŒ¨ (ì†ë„ ì €í•˜ ê°€ëŠ¥ì„±): {e}")

        logger.info("FLUX.2 íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ.")
        return self.pipeline

    def run_img2img(self, image: Image.Image, prompt: str) -> Image.Image:
        """
        FLUX.2ë¥¼ ì‚¬ìš©í•˜ì—¬ Image-to-Image ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        pipe = self.load_pipeline()

        full_inference_start = time.time()

        # 1. í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© (ì›ê²© API ì‚¬ìš©)
        # prompt_embeds = self._remote_text_encoder(prompt)
        # if prompt_embeds is None:
        #     raise ValueError("Remote Text Encoder failed to generate embeddings.")

        diffusion_start_time = time.time()

        # with profile(
        #     activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
        #     record_shapes=True, profile_memory=True, with_stack=False
        # ) as prof:
        #     with record_function("FLUX_INFERENCE"):
        #         result_image = pipe(
        #             prompt=prompt,
        #             image=image, 
        #             guidance_scale=4.0, 
        #             num_inference_steps=20, 
        #         ).images[0]

        result_image = pipe(
                    prompt=prompt,
                    image=image, 
                    guidance_scale=4.0, 
                    num_inference_steps=20, 
                ).images[0]

        # 3. í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ì €ì¥ (Chrome Trace Format)
        # current_time_after_inference = time.time()

        # logger.info("\n\n============ ğŸ“Š FLUX.2 GPU Profiling Results (Top 10) ============")
        
        # # 'cuda_time_total' ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ëŠë¦° CUDA ì—°ì‚°ì„ ì°¾ìŠµë‹ˆë‹¤.
        # logger.info(prof.key_averages(group_by_input_shape=False).table(
        #     sort_by="cuda_time_total", row_limit=10
        # ))
        # logger.info("==================================================================")

        diffusion_duration = time.time() - diffusion_start_time 
        full_inference_duration = time.time() - full_inference_start

        logger.info(f"â±ï¸ Diffusion Model (UNet+VAE) Time: {diffusion_duration:.2f}s")
        logger.info(f"â±ï¸ Full Img2Img Time (Encoder+Diffusion): {full_inference_duration:.2f}s")

        return result_image

# ----------------------------------------------------
# [ê¸°ì¡´ ì½”ë“œ ë³€ê²½ í›„ í˜¸í™˜ì„± ìœ ì§€ë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜]
# ----------------------------------------------------

def load_pipeline():
    """ì™¸ë¶€ í˜¸í™˜ì„±ì„ ìœ„í•´ Flux2ImageGenerator ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    return Flux2ImageGenerator().load_pipeline()

def run_inpainting(image: Image.Image, mask_image: Image.Image, prompt: str) -> Image.Image:
    """
    ì™¸ë¶€ í˜¸í™˜ì„± ìœ ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ëª…ì€ run_inpaintingì„ ì‚¬ìš©í•˜ì§€ë§Œ, 
    ë‚´ë¶€ì ìœ¼ë¡œëŠ” FLUX.2 Img2Img ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (mask_imageëŠ” ë¬´ì‹œ)
    """
    generator = Flux2ImageGenerator()
    return generator.run_img2img(image, prompt)