/usr/local/lib/python3.11/dist-packages/celery/platforms.py:841: SecurityWarning: You're running the worker with superuser privileges: this is
absolutely not recommended!

Please specify a different user using the --uid option.

User information: uid=0 euid=0 gid=0 egid=0

  warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(
 
 -------------- celery@77da2b6105c4 v5.6.0 (recovery)
--- ***** ----- 
-- ******* ---- Linux-6.5.0-35-generic-x86_64-with-glibc2.35 2025-12-17 11:38:15
- *** --- * --- 
- ** ---------- [config]
- ** ---------- .> app:         tasks:0x7bbb7b677c90
- ** ---------- .> transport:   redis://localhost:6379/0
- ** ---------- .> results:     redis://localhost:6379/0
- *** --- * --- .> concurrency: 2 (prefork)
-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
--- ***** ----- 
 -------------- [queues]
                .> celery           exchange=celery(direct) key=celery
                

[tasks]
  . app.tasks.run_agent_task

[2025-12-17 11:38:16,194: INFO/MainProcess] Connected to redis://localhost:6379/0
[2025-12-17 11:38:16,197: INFO/MainProcess] mingle: searching for neighbors
[2025-12-17 11:38:17,204: INFO/MainProcess] mingle: all alone
[2025-12-17 11:38:17,211: INFO/MainProcess] celery@77da2b6105c4 ready.
[2025-12-17 11:38:17,218: INFO/MainProcess] Task app.tasks.run_agent_task[b8c9d007-f193-4f64-b9cb-dc2d69af7b60] received
[2025-12-17 11:38:17,225: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[b8c9d007-f193-4f64-b9cb-dc2d69af7b60] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,233: INFO/MainProcess] Task app.tasks.run_agent_task[05e82727-81d4-4c8c-a88e-e693a51ec017] received
[2025-12-17 11:38:17,236: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[05e82727-81d4-4c8c-a88e-e693a51ec017] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,241: INFO/MainProcess] Task app.tasks.run_agent_task[f7f93690-2d20-42b2-81e4-16f619b52d1b] received
[2025-12-17 11:38:17,244: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[f7f93690-2d20-42b2-81e4-16f619b52d1b] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,248: INFO/MainProcess] Task app.tasks.run_agent_task[811a2621-aac4-4b62-bd33-45c1d3cd9635] received
[2025-12-17 11:38:17,251: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[811a2621-aac4-4b62-bd33-45c1d3cd9635] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,255: INFO/MainProcess] Task app.tasks.run_agent_task[a9baaa85-3acb-4c54-b210-4317e34df3c6] received
[2025-12-17 11:38:17,258: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[a9baaa85-3acb-4c54-b210-4317e34df3c6] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,262: INFO/MainProcess] Task app.tasks.run_agent_task[93b21f61-6686-4ab1-8556-8199978f2be5] received
[2025-12-17 11:38:17,265: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[93b21f61-6686-4ab1-8556-8199978f2be5] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,272: INFO/MainProcess] Task app.tasks.run_agent_task[bb3b2f43-7bd8-4c9a-bf22-13f90d038574] received
[2025-12-17 11:38:17,275: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[bb3b2f43-7bd8-4c9a-bf22-13f90d038574] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,282: INFO/MainProcess] Task app.tasks.run_agent_task[7a1dc822-cfd2-4b00-8aaf-2b0699c2fbae] received
[2025-12-17 11:38:17,286: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[7a1dc822-cfd2-4b00-8aaf-2b0699c2fbae] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,293: INFO/MainProcess] Task app.tasks.run_agent_task[1c3bf3c0-eea3-4c55-86e4-baace88dd2b2] received
[2025-12-17 11:38:17,297: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[1c3bf3c0-eea3-4c55-86e4-baace88dd2b2] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,302: INFO/MainProcess] Task app.tasks.run_agent_task[d5947709-f9dd-4665-8051-f4aeb01bcec4] received
[2025-12-17 11:38:17,304: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[d5947709-f9dd-4665-8051-f4aeb01bcec4] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,309: INFO/MainProcess] Task app.tasks.run_agent_task[97b95b0b-d2a9-4d08-a212-454526d0a3a4] received
[2025-12-17 11:38:17,312: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[97b95b0b-d2a9-4d08-a212-454526d0a3a4] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,319: INFO/MainProcess] Task app.tasks.run_agent_task[fcd11135-8c5d-488f-b306-f3ca1d12668e] received
[2025-12-17 11:38:17,322: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[fcd11135-8c5d-488f-b306-f3ca1d12668e] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,328: INFO/MainProcess] Task app.tasks.run_agent_task[5ec920bd-d2ba-4f0b-a666-730b7abbdd17] received
[2025-12-17 11:38:17,332: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[5ec920bd-d2ba-4f0b-a666-730b7abbdd17] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,338: INFO/MainProcess] Task app.tasks.run_agent_task[4beb105a-2593-4f5a-a588-724fdcf2a082] received
[2025-12-17 11:38:17,341: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[4beb105a-2593-4f5a-a588-724fdcf2a082] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,347: INFO/MainProcess] Task app.tasks.run_agent_task[64a8e009-7df2-470b-8039-a00f37cac03c] received
[2025-12-17 11:38:17,350: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[64a8e009-7df2-470b-8039-a00f37cac03c] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,357: INFO/MainProcess] Task app.tasks.run_agent_task[68bee74a-c405-43b0-b403-cdb1ff64716b] received
[2025-12-17 11:38:17,360: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[68bee74a-c405-43b0-b403-cdb1ff64716b] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,366: INFO/MainProcess] Task app.tasks.run_agent_task[c7b196a3-7abf-4426-bbff-325401013fe9] received
[2025-12-17 11:38:17,369: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[c7b196a3-7abf-4426-bbff-325401013fe9] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,374: INFO/MainProcess] Task app.tasks.run_agent_task[a4024a48-825d-47a9-98a5-42349f97cb02] received
[2025-12-17 11:38:17,377: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[a4024a48-825d-47a9-98a5-42349f97cb02] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,383: INFO/MainProcess] Task app.tasks.run_agent_task[bd56a121-ce1e-4871-a337-288e261214a0] received
[2025-12-17 11:38:17,385: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[bd56a121-ce1e-4871-a337-288e261214a0] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,390: INFO/MainProcess] Task app.tasks.run_agent_task[e974d996-4e62-44e8-805b-b5f12959bdb2] received
[2025-12-17 11:38:17,393: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[e974d996-4e62-44e8-805b-b5f12959bdb2] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,398: INFO/MainProcess] Task app.tasks.run_agent_task[c5dd40ce-a37f-43a5-af20-82f2df69c291] received
[2025-12-17 11:38:17,400: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[c5dd40ce-a37f-43a5-af20-82f2df69c291] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,408: INFO/MainProcess] Task app.tasks.run_agent_task[33a19178-f8d2-4b47-93d3-91f3c58b142f] received
[2025-12-17 11:38:17,412: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[33a19178-f8d2-4b47-93d3-91f3c58b142f] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,420: INFO/MainProcess] Task app.tasks.run_agent_task[bb25c5bf-1523-47bb-937e-a4b87bafb587] received
[2025-12-17 11:38:17,423: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[bb25c5bf-1523-47bb-937e-a4b87bafb587] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,432: INFO/MainProcess] Task app.tasks.run_agent_task[f5ad70cb-2570-4d74-98be-dfb1c1bf7e37] received
[2025-12-17 11:38:17,435: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[f5ad70cb-2570-4d74-98be-dfb1c1bf7e37] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,440: INFO/MainProcess] Task app.tasks.run_agent_task[3d1a4a1a-2ad2-4e79-9de7-7da2a0891dba] received
[2025-12-17 11:38:17,443: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[3d1a4a1a-2ad2-4e79-9de7-7da2a0891dba] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,447: INFO/MainProcess] Task app.tasks.run_agent_task[95e962a4-440e-45c7-9cbb-bcab0b21936d] received
[2025-12-17 11:38:17,450: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[95e962a4-440e-45c7-9cbb-bcab0b21936d] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,454: INFO/MainProcess] Task app.tasks.run_agent_task[2ecdecfb-cf98-426d-8a82-dc33fd630f21] received
[2025-12-17 11:38:17,456: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[2ecdecfb-cf98-426d-8a82-dc33fd630f21] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,463: INFO/MainProcess] Task app.tasks.run_agent_task[a9a9e88f-a8bb-44a6-938a-766c3be391ba] received
[2025-12-17 11:38:17,465: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[a9a9e88f-a8bb-44a6-938a-766c3be391ba] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,472: INFO/MainProcess] Task app.tasks.run_agent_task[bb828f27-d63c-47aa-8e7d-b21d7445aa3e] received
[2025-12-17 11:38:17,474: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[bb828f27-d63c-47aa-8e7d-b21d7445aa3e] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,480: INFO/MainProcess] Task app.tasks.run_agent_task[320b1e7c-8981-490c-b43d-d93d9c83200a] received
[2025-12-17 11:38:17,483: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[320b1e7c-8981-490c-b43d-d93d9c83200a] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,489: INFO/MainProcess] Task app.tasks.run_agent_task[ac1bff96-3b87-4cf0-a842-c159b82d22a0] received
[2025-12-17 11:38:17,491: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[ac1bff96-3b87-4cf0-a842-c159b82d22a0] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,496: INFO/MainProcess] Task app.tasks.run_agent_task[b2de7783-1207-488d-a959-a49122cf4655] received
[2025-12-17 11:38:17,498: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[b2de7783-1207-488d-a959-a49122cf4655] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,503: INFO/MainProcess] Task app.tasks.run_agent_task[4bac0bbd-fa26-442f-b717-39de8f8eedcc] received
[2025-12-17 11:38:17,506: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[4bac0bbd-fa26-442f-b717-39de8f8eedcc] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,510: INFO/MainProcess] Task app.tasks.run_agent_task[cb72d3f7-3029-4642-8e59-d1f388301959] received
[2025-12-17 11:38:17,513: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[cb72d3f7-3029-4642-8e59-d1f388301959] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,517: INFO/MainProcess] Task app.tasks.run_agent_task[2eb5c45b-0a73-4e1a-b037-010b7dd30299] received
[2025-12-17 11:38:17,520: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[2eb5c45b-0a73-4e1a-b037-010b7dd30299] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,524: INFO/MainProcess] Task app.tasks.run_agent_task[d9afbd1e-5b35-4ff4-a1b8-9a8078a009e3] received
[2025-12-17 11:38:17,527: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[d9afbd1e-5b35-4ff4-a1b8-9a8078a009e3] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,533: INFO/MainProcess] Task app.tasks.run_agent_task[eedb79db-e2a4-48a5-bb8c-7d19d029fc07] received
[2025-12-17 11:38:17,537: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[eedb79db-e2a4-48a5-bb8c-7d19d029fc07] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,544: INFO/MainProcess] Task app.tasks.run_agent_task[365d3c59-07e6-42e0-b5b8-47460ce2425c] received
[2025-12-17 11:38:17,547: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[365d3c59-07e6-42e0-b5b8-47460ce2425c] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,553: INFO/MainProcess] Task app.tasks.run_agent_task[641a2a11-cc5d-4899-8cd3-95e8627b85b8] received
[2025-12-17 11:38:17,557: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[641a2a11-cc5d-4899-8cd3-95e8627b85b8] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,561: INFO/MainProcess] Task app.tasks.run_agent_task[c59fcc2a-bfdb-4eec-a0b4-4da05771a443] received
[2025-12-17 11:38:17,564: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[c59fcc2a-bfdb-4eec-a0b4-4da05771a443] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,568: INFO/MainProcess] Task app.tasks.run_agent_task[66530888-d941-4d08-9099-5c92141bd376] received
[2025-12-17 11:38:17,571: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[66530888-d941-4d08-9099-5c92141bd376] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,575: INFO/MainProcess] Task app.tasks.run_agent_task[e4aa17cc-bcfd-4e53-a45e-3cada9f25367] received
[2025-12-17 11:38:17,577: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[e4aa17cc-bcfd-4e53-a45e-3cada9f25367] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,583: INFO/MainProcess] Task app.tasks.run_agent_task[43de89fc-a591-46cf-a2dc-8cdfadfb2fb1] received
[2025-12-17 11:38:17,587: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[43de89fc-a591-46cf-a2dc-8cdfadfb2fb1] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,593: INFO/MainProcess] Task app.tasks.run_agent_task[ece43c5d-9ec7-4b7b-a902-9887155f3cd5] received
[2025-12-17 11:38:17,596: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[ece43c5d-9ec7-4b7b-a902-9887155f3cd5] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,603: INFO/MainProcess] Task app.tasks.run_agent_task[964bef00-d258-45a3-85d9-3d5db4e7af45] received
[2025-12-17 11:38:17,606: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[964bef00-d258-45a3-85d9-3d5db4e7af45] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,611: INFO/MainProcess] Task app.tasks.run_agent_task[7f076daa-fbb8-4c45-a43c-8e32888f531b] received
[2025-12-17 11:38:17,613: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[7f076daa-fbb8-4c45-a43c-8e32888f531b] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,618: INFO/MainProcess] Task app.tasks.run_agent_task[a8719c30-7a21-4d6c-893e-ff05fa5d925e] received
[2025-12-17 11:38:17,621: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[a8719c30-7a21-4d6c-893e-ff05fa5d925e] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,625: INFO/MainProcess] Task app.tasks.run_agent_task[c47f7946-c7d9-46ae-a5d4-934474f4d13b] received
[2025-12-17 11:38:17,628: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[c47f7946-c7d9-46ae-a5d4-934474f4d13b] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,633: INFO/MainProcess] Task app.tasks.run_agent_task[c397f757-a37d-4569-8cea-8f523db59488] received
[2025-12-17 11:38:17,635: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[c397f757-a37d-4569-8cea-8f523db59488] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,641: INFO/MainProcess] Task app.tasks.run_agent_task[3d1dfd38-969f-4f08-b6ad-a030a1992983] received
[2025-12-17 11:38:17,644: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[3d1dfd38-969f-4f08-b6ad-a030a1992983] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,648: INFO/MainProcess] Task app.tasks.run_agent_task[cf9e523f-9902-4d04-ad37-96b1ecbced15] received
[2025-12-17 11:38:17,651: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[cf9e523f-9902-4d04-ad37-96b1ecbced15] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,663: INFO/MainProcess] Task app.tasks.run_agent_task[172187fb-ade2-49a6-9e7f-4ef6b25a29c3] received
[2025-12-17 11:38:17,667: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[172187fb-ade2-49a6-9e7f-4ef6b25a29c3] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,674: INFO/MainProcess] Task app.tasks.run_agent_task[8fa2a098-2a17-45dd-99d4-2a9b45d926e9] received
[2025-12-17 11:38:17,677: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[8fa2a098-2a17-45dd-99d4-2a9b45d926e9] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,684: INFO/MainProcess] Task app.tasks.run_agent_task[e333e79b-e467-4f6d-820f-8fcf71912403] received
[2025-12-17 11:38:17,687: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[e333e79b-e467-4f6d-820f-8fcf71912403] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,691: INFO/MainProcess] Task app.tasks.run_agent_task[7d5407f0-e231-47ad-8ebe-93c0b1b70490] received
[2025-12-17 11:38:17,694: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[7d5407f0-e231-47ad-8ebe-93c0b1b70490] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,698: INFO/MainProcess] Task app.tasks.run_agent_task[7c5a40ad-8aa0-491e-b55d-f0928f7fd943] received
[2025-12-17 11:38:17,701: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[7c5a40ad-8aa0-491e-b55d-f0928f7fd943] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,705: INFO/MainProcess] Task app.tasks.run_agent_task[2fc5445e-9f8b-406f-8993-932caa7da16d] received
[2025-12-17 11:38:17,708: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[2fc5445e-9f8b-406f-8993-932caa7da16d] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,714: INFO/MainProcess] Task app.tasks.run_agent_task[d494dd1d-1a4a-4005-b1c0-a032b4a74ddf] received
[2025-12-17 11:38:17,717: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[d494dd1d-1a4a-4005-b1c0-a032b4a74ddf] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,723: INFO/MainProcess] Task app.tasks.run_agent_task[4afb7522-a02b-42ee-9c37-f11eb030c3c6] received
[2025-12-17 11:38:17,726: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[4afb7522-a02b-42ee-9c37-f11eb030c3c6] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,733: INFO/MainProcess] Task app.tasks.run_agent_task[b3748cd1-67a5-413b-ba99-6f2dd4dd4a2a] received
[2025-12-17 11:38:17,736: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[b3748cd1-67a5-413b-ba99-6f2dd4dd4a2a] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,741: INFO/MainProcess] Task app.tasks.run_agent_task[78a097c9-22d1-4388-a7c8-e356221c1814] received
[2025-12-17 11:38:17,744: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[78a097c9-22d1-4388-a7c8-e356221c1814] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,749: INFO/MainProcess] Task app.tasks.run_agent_task[38226547-47cf-472c-ba99-1a3be411a85e] received
[2025-12-17 11:38:17,752: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[38226547-47cf-472c-ba99-1a3be411a85e] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,757: INFO/MainProcess] Task app.tasks.run_agent_task[afd58bce-5abb-429c-9664-b02e71df3a67] received
[2025-12-17 11:38:17,759: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[afd58bce-5abb-429c-9664-b02e71df3a67] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,764: INFO/MainProcess] Task app.tasks.run_agent_task[14834bd0-0314-4fb6-a817-2a656e42def0] received
[2025-12-17 11:38:17,767: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[14834bd0-0314-4fb6-a817-2a656e42def0] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,771: INFO/MainProcess] Task app.tasks.run_agent_task[640a9c3d-8838-4650-8580-3a243eec512f] received
[2025-12-17 11:38:17,774: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[640a9c3d-8838-4650-8580-3a243eec512f] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,778: INFO/MainProcess] Task app.tasks.run_agent_task[362f8d6b-eca8-48e8-8123-3b40f95e3cca] received
[2025-12-17 11:38:17,781: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[362f8d6b-eca8-48e8-8123-3b40f95e3cca] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,787: INFO/MainProcess] Task app.tasks.run_agent_task[00d8dd9e-9518-4261-b456-8baadf11f31d] received
[2025-12-17 11:38:17,791: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[00d8dd9e-9518-4261-b456-8baadf11f31d] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,797: INFO/MainProcess] Task app.tasks.run_agent_task[199e0db8-97b5-4d7e-a588-723153382af0] received
[2025-12-17 11:38:17,800: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[199e0db8-97b5-4d7e-a588-723153382af0] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,807: INFO/MainProcess] Task app.tasks.run_agent_task[96924d44-06a5-4642-8a15-2847e855b056] received
[2025-12-17 11:38:17,810: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[96924d44-06a5-4642-8a15-2847e855b056] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,815: INFO/MainProcess] Task app.tasks.run_agent_task[906dc16b-dd62-43b1-aadb-78c09b0a23f5] received
[2025-12-17 11:38:17,817: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[906dc16b-dd62-43b1-aadb-78c09b0a23f5] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,821: INFO/MainProcess] Task app.tasks.run_agent_task[0b07ca4f-f46d-4f92-80b8-b02d71f69af4] received
[2025-12-17 11:38:17,824: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[0b07ca4f-f46d-4f92-80b8-b02d71f69af4] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,829: INFO/MainProcess] Task app.tasks.run_agent_task[d40cabd7-3c1b-4cb3-a52b-9f2cffc851d7] received
[2025-12-17 11:38:17,831: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[d40cabd7-3c1b-4cb3-a52b-9f2cffc851d7] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,837: INFO/MainProcess] Task app.tasks.run_agent_task[3b8cb45c-8a81-43fc-8903-9239913a9e7c] received
[2025-12-17 11:38:17,841: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[3b8cb45c-8a81-43fc-8903-9239913a9e7c] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,846: INFO/MainProcess] Task app.tasks.run_agent_task[7564fbe7-5f01-4b3e-889a-ed1a564456f1] received
[2025-12-17 11:38:17,849: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[7564fbe7-5f01-4b3e-889a-ed1a564456f1] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,856: INFO/MainProcess] Task app.tasks.run_agent_task[090e03e2-c61d-4816-b397-bd47717a4ede] received
[2025-12-17 11:38:17,859: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[090e03e2-c61d-4816-b397-bd47717a4ede] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,864: INFO/MainProcess] Task app.tasks.run_agent_task[633f4881-8d33-428c-b8d9-6e48f3ea8017] received
[2025-12-17 11:38:17,867: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[633f4881-8d33-428c-b8d9-6e48f3ea8017] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,872: INFO/MainProcess] Task app.tasks.run_agent_task[a645cb42-a77f-491b-ba4d-ea04c63ecc70] received
[2025-12-17 11:38:17,875: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[a645cb42-a77f-491b-ba4d-ea04c63ecc70] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,879: INFO/MainProcess] Task app.tasks.run_agent_task[1f3ee019-abe4-4437-9547-5317398bc9c4] received
[2025-12-17 11:38:17,882: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[1f3ee019-abe4-4437-9547-5317398bc9c4] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,887: INFO/MainProcess] Task app.tasks.run_agent_task[381326b9-7d2e-412c-a3e6-95bf5b01ea04] received
[2025-12-17 11:38:17,890: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[381326b9-7d2e-412c-a3e6-95bf5b01ea04] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,894: INFO/MainProcess] Task app.tasks.run_agent_task[5487d82c-353c-4999-847e-0773cfc692c9] received
[2025-12-17 11:38:17,897: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[5487d82c-353c-4999-847e-0773cfc692c9] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,901: INFO/MainProcess] Task app.tasks.run_agent_task[e5207744-b449-4b91-bf88-d915333124de] received
[2025-12-17 11:38:17,904: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[e5207744-b449-4b91-bf88-d915333124de] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,910: INFO/MainProcess] Task app.tasks.run_agent_task[ba392544-514b-4f69-8e1f-f5475cf173b5] received
[2025-12-17 11:38:17,914: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[ba392544-514b-4f69-8e1f-f5475cf173b5] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,920: INFO/MainProcess] Task app.tasks.run_agent_task[41be36bb-a3e7-4dba-b9a6-fb2c34e28f81] received
[2025-12-17 11:38:17,923: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[41be36bb-a3e7-4dba-b9a6-fb2c34e28f81] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,930: INFO/MainProcess] Task app.tasks.run_agent_task[806d4016-2ba8-40d8-b274-da26fb95de75] received
[2025-12-17 11:38:17,934: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[806d4016-2ba8-40d8-b274-da26fb95de75] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,938: INFO/MainProcess] Task app.tasks.run_agent_task[f51a752a-2cea-42e9-ab39-d2b9ca01e0c0] received
[2025-12-17 11:38:17,941: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[f51a752a-2cea-42e9-ab39-d2b9ca01e0c0] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,945: INFO/MainProcess] Task app.tasks.run_agent_task[b6f8fcd2-e889-46ce-82d4-35e730319285] received
[2025-12-17 11:38:17,948: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[b6f8fcd2-e889-46ce-82d4-35e730319285] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,952: INFO/MainProcess] Task app.tasks.run_agent_task[e2a5ef47-08cc-4f8b-a797-18e3f481bf0b] received
[2025-12-17 11:38:17,955: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[e2a5ef47-08cc-4f8b-a797-18e3f481bf0b] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,962: INFO/MainProcess] Task app.tasks.run_agent_task[cd41ccda-a176-4a66-83bc-040337ec43b2] received
[2025-12-17 11:38:17,965: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[cd41ccda-a176-4a66-83bc-040337ec43b2] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,971: INFO/MainProcess] Task app.tasks.run_agent_task[b6b802e8-70be-4b97-98dc-ffef69b4bd26] received
[2025-12-17 11:38:17,974: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[b6b802e8-70be-4b97-98dc-ffef69b4bd26] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,980: INFO/MainProcess] Task app.tasks.run_agent_task[dd7c545f-ee97-42fd-acb9-62307688356e] received
[2025-12-17 11:38:17,983: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[dd7c545f-ee97-42fd-acb9-62307688356e] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,988: INFO/MainProcess] Task app.tasks.run_agent_task[44a30dec-2994-4d05-af6e-b852c4242f81] received
[2025-12-17 11:38:17,991: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[44a30dec-2994-4d05-af6e-b852c4242f81] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:17,996: INFO/MainProcess] Task app.tasks.run_agent_task[832ab2dd-80ca-43c9-9343-853f1aff9381] received
[2025-12-17 11:38:17,999: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[832ab2dd-80ca-43c9-9343-853f1aff9381] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,003: INFO/MainProcess] Task app.tasks.run_agent_task[5636eaae-3a3b-44bb-a328-99469d4a8c34] received
[2025-12-17 11:38:18,006: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[5636eaae-3a3b-44bb-a328-99469d4a8c34] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,011: INFO/MainProcess] Task app.tasks.run_agent_task[2a6908f9-f809-4a4e-8d7d-43c472a7de55] received
[2025-12-17 11:38:18,014: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[2a6908f9-f809-4a4e-8d7d-43c472a7de55] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,018: INFO/MainProcess] Task app.tasks.run_agent_task[c3155800-1f53-48bf-8a80-6c52bb4849ca] received
[2025-12-17 11:38:18,021: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[c3155800-1f53-48bf-8a80-6c52bb4849ca] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,025: INFO/MainProcess] Task app.tasks.run_agent_task[9b6ef8db-d9cd-4dab-ac40-448776d39cdb] received
[2025-12-17 11:38:18,028: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[9b6ef8db-d9cd-4dab-ac40-448776d39cdb] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,034: INFO/MainProcess] Task app.tasks.run_agent_task[058837d8-517c-4ff2-bc00-60cd3385abdb] received
[2025-12-17 11:38:18,038: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[058837d8-517c-4ff2-bc00-60cd3385abdb] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,043: INFO/MainProcess] Task app.tasks.run_agent_task[d6010166-e516-4de9-b953-8f643e390630] received
[2025-12-17 11:38:18,046: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[d6010166-e516-4de9-b953-8f643e390630] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,053: INFO/MainProcess] Task app.tasks.run_agent_task[65471c55-c003-4c3c-9804-829a76b8f493] received
[2025-12-17 11:38:18,056: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[65471c55-c003-4c3c-9804-829a76b8f493] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,060: INFO/MainProcess] Task app.tasks.run_agent_task[ae7c1e8e-8d3b-4962-9203-6ff349828cec] received
[2025-12-17 11:38:18,063: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[ae7c1e8e-8d3b-4962-9203-6ff349828cec] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,067: INFO/MainProcess] Task app.tasks.run_agent_task[26c79f1c-3ff2-46c4-b246-9baf8803eaa1] received
[2025-12-17 11:38:18,070: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[26c79f1c-3ff2-46c4-b246-9baf8803eaa1] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,074: INFO/MainProcess] Task app.tasks.run_agent_task[3cf39b3e-6a6c-40bb-82cc-9e6ac47ea73f] received
[2025-12-17 11:38:18,076: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[3cf39b3e-6a6c-40bb-82cc-9e6ac47ea73f] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,083: INFO/MainProcess] Task app.tasks.run_agent_task[b236af48-0af1-41ac-99c1-5ac09e5c85dc] received
[2025-12-17 11:38:18,086: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[b236af48-0af1-41ac-99c1-5ac09e5c85dc] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,092: INFO/MainProcess] Task app.tasks.run_agent_task[5e4bf66d-e2ae-43eb-8733-266173ed6a46] received
[2025-12-17 11:38:18,095: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[5e4bf66d-e2ae-43eb-8733-266173ed6a46] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
[2025-12-17 11:38:18,101: INFO/MainProcess] Task app.tasks.run_agent_task[0ab0b055-d7b6-4859-83b6-83636e9e23a5] received
[2025-12-17 11:38:18,104: ERROR/ForkPoolWorker-1] Task app.tasks.run_agent_task[0ab0b055-d7b6-4859-83b6-83636e9e23a5] raised unexpected: RuntimeError("Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method")
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/celery/app/trace.py", line 779, in __protected_call__
    return self.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/Interactive-AI-Agent/backend/app/tasks.py", line 47, in run_agent_task
    torch.cuda.reset_peak_memory_stats()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py", line 321, in reset_peak_memory_stats
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index
    return _torch_get_device_index(device, optional, allow_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 801, in _get_device_index
    device_idx = _get_current_device_index()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in _get_current_device_index
    return _get_device_attr(lambda m: m.current_device())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 727, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 740, in <lambda>
    return _get_device_attr(lambda m: m.current_device())
                                      ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 878, in current_device
    _lazy_init()
  File "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py", line 300, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method

worker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!

worker: Warm shutdown (MainProcess)

worker: Hitting Ctrl+C again will terminate all running tasks!
